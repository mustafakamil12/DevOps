from confluent_kafka import SerializingProducer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.schema_registry.avro import AvroSerializer
import json

# Kafka & Schema Registry Configuration
kafka_brokers = 'kafka1.xyz.com:443,kafka2.xyz.com:443,kafka3.xyz.com:443'
schema_registry_url = 'https://schema-registry.xyz.com'

# Initialize Schema Registry
schema_registry_conf = {'url': schema_registry_url}
schema_registry_client = SchemaRegistryClient(schema_registry_conf)

# Define Avro Schema (Replace with your actual schema)
avro_schema_str = """
{
  "type": "record",
  "name": "TestMessage",
  "fields": [
    {"name": "id", "type": "int"},
    {"name": "message", "type": "string"}
  ]
}
"""

# Create Avro Serializer
avro_serializer = AvroSerializer(schema_registry_client, avro_schema_str)

# Kafka Producer Config
producer_conf = {
    'bootstrap.servers': kafka_brokers,
    'security.protocol': 'SSL',
    'ssl.ca.location': 'CARoot.pem',
    'ssl.certificate.location': 'certificate.pem',
    'ssl.key.location': 'key.pem',
    'ssl.key.password': 'welcome123',
    'key.serializer': lambda k: str(k).encode('utf-8'),  # Key must be bytes
    'value.serializer': avro_serializer,  # Value is serialized as Avro
}

producer = SerializingProducer(producer_conf)

# Avro message
message = {"id": 1, "message": "Hello Kafka!"}

# Send Message
producer.produce(topic='test-topic', key="key1", value=message)
producer.flush()
